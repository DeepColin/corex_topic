{
 "metadata": {
  "name": "",
  "signature": "sha256:3bc7ec8a7c75758f5eaf5fa10e53b8f94cc1c5adc8d36b5be48469e7ff4a4747"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Anchored CorEx: Topic Modeling with Minimal Domain Knowledge"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Author: Ryan J. Gallagher, 07/06/2017"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook walks through how to use the CorEx topic model code. This includes fitting CorEx to your data, examining the topic model output, outputting results, and anchoring words to topics. It is assumed that the corex_topic and vis_topic code is in your working directory, and that you have numpy, scipy, and scikit-learn installed. \n",
      "\n",
      "Details of the CorEx topic model can be found in our paper:\n",
      "[*Anchored Correlation Explanation: Topic Modeling with Minimal Domain Knowledge*](https://arxiv.org/abs/1611.10277), preprint 2017."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "while 'Desktop' not in os.listdir(os.getcwd()):\n",
      "    os.chdir('..')\n",
      "os.chdir('Desktop/corex_topic')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import vis_topic as vt\n",
      "import corex_topic as ct\n",
      "import scipy.sparse as ss\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading the 20 Newsgroups Dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need to first load our data to run the CorEx topic model. We'll use the 20 Newsgroups dataset, which scikit-learn provides functionality to acess."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get 20 newsgroups data\n",
      "newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The topic model assumes input is in the form of a doc-term matrix, where rows are documents and columns are binary counts. We'll vectorize the newsgroups data and convert it to a sparse matrix to save on memory usage. Note, we use binary count vectors as input to the CorEx topic model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Transform 20 newsgroup data into a sparse matrix\n",
      "vectorizer = CountVectorizer(stop_words='english', max_features = 20000, binary = True)\n",
      "doc_word = vectorizer.fit_transform(newsgroups.data)\n",
      "doc_word = ss.csr_matrix(doc_word)\n",
      "\n",
      "doc_word.shape # n_docs x m_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "(11314, 20000)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our doc-word matrix is 11,314 documents by 101,322 words. Let's get the words that label the columns. We'll need these for outputting readable topics and later for anchoring."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get words that label the columns (needed to extract readable topics)\n",
      "words = list(np.asarray(vectorizer.get_feature_names()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "CorEx Topic Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The main paramters of the CorEx topic model are:\n",
      "+ **n_hidden**: number of topics (\"hidden\" as in \"hidden latent topics\")\n",
      "+ **words**: words that label the columns of the doc-word matrix\n",
      "+ **max_iter**: number of iterations to run through the update equations\n",
      "+ **verbose**:  if *verbose=1*, then CorEx will print the TCs with each iteration\n",
      "+ **seed**:     random number seed to use for model initialization\n",
      "\n",
      "We'll train a topic model with 50 topics that iterates up to200 times. (This will take a few minutes.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_model = ct.Corex(n_hidden=20, words=words, max_iter=200, verbose=False, seed=None)\n",
      "topic_model.fit(doc_word, words=words);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "CorEx Output"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The CorEx topic model provides functionality for easily accessing the topics. Let's take a look one of the topics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print a single topic from CorEx topic model\n",
      "topic_model.get_topics(topic=5, n_words=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[(u'windows', 0.098693231114866456),\n",
        " (u'file', 0.057837756413923226),\n",
        " (u'dos', 0.053944761810679746),\n",
        " (u'files', 0.051054068565401851),\n",
        " (u'program', 0.045818888540261123),\n",
        " (u'ftp', 0.040263613665403278),\n",
        " (u'software', 0.040197513607973197),\n",
        " (u'unix', 0.033932768498652233),\n",
        " (u'window', 0.033339739420547118),\n",
        " (u'graphics', 0.030942793635717426)]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These words have the highest *mutual information* with the topic, rather than being the highest probability words as in LDA. The mutual information with the topic is the number reported in each tuple. If the column labels have not been specified, then the code will return the column indices for the top words in each topic.\n",
      "\n",
      "We can also retrieve all of the topics at once if we would like."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print all topics from the CorEx topic model\n",
      "topics = topic_model.get_topics()\n",
      "for n,topic in enumerate(topics):\n",
      "    topic_words,_ = zip(*topic)\n",
      "    print '{}: '.format(n) + ','.join(topic_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: d9,ei,1t,mw,mq,wm,m9,m3,lj,m_\n",
        "1: 92,86,70,77,63,80,91,82,81,96\n",
        "2: 15,13,10,11,14,20,18,12,1993,19\n",
        "3: card,drive,disk,ram,scsi,controller,pc,video,mac,computer\n",
        "4: god,jesus,bible,christ,christians,christian,church,faith,christianity,sin\n",
        "5: windows,file,dos,files,program,ftp,software,unix,window,graphics\n",
        "6: team,game,season,players,games,league,play,hockey,teams,player\n",
        "7: armenians,armenian,turkish,argic,serdar,armenia,turks,history,genocide,turkey\n",
        "8: national,april,united,press,international,research,members,president,center,policy\n",
        "9: government,law,rights,state,gun,crime,police,laws,weapons,legal\n",
        "10: using,problem,set,work,code,running,run,problems,user,function\n",
        "11: 1992,published,june,university,dr,1988,pp,1989,1990,special\n",
        "12: archive,anonymous,modified,basic,answers,faq,multiple,sites,versions,description\n",
        "13: used,systems,technology,provide,control,contact,provides,development,required,technical\n",
        "14: encryption,key,clipper,public,keys,secure,nsa,security,escrow,secret\n",
        "15: sale,shipping,100,condition,price,offer,includes,sell,unit,digital\n",
        "16: fact,point,case,example,important,claim,means,real,situation,matter\n",
        "17: including,following,order,based,note,list,present,various,free,include\n",
        "18: life,children,death,human,religion,men,religious,killed,women,evidence\n",
        "19: year,los,york,angeles,city,san,washington,st,division,boston\n",
        "20: general,science,issue,scientific,groups,studies,result,group,related,process\n",
        "21: space,nasa,orbit,launch,earth,moon,shuttle,lunar,satellite,flight\n",
        "22: pitt,geb,chastity,n3jxp,dsl,gordon,cadre,intellect,shameful,skepticism\n",
        "23: said,did,away,man,place,today,asked,letter,stop,outside\n",
        "24: war,military,population,army,soldiers,soviet,armed,troops,arms,forces\n",
        "25: people,country,live,political,society,anti,sense,words,argument,nature\n",
        "26: say,make,person,saying,mean,agree,making,clear,makes,mind\n",
        "27: years,long,large,high,house,small,force,open,000,area\n",
        "28: world,given,taken,subject,entire,established,john,role,began,foundation\n",
        "29: does,read,different,true,non,simply,called,trying,word,support\n",
        "30: israel,israeli,jews,arab,jewish,arabs,peace,land,israelis,nazi\n",
        "31: mail,information,send,use,available,address,internet,phone,data,access\n",
        "32: went,later,second,took,left,came,power,days,head,hit\n",
        "33: going,better,ve,little,look,let,got,far,ll,didn\n",
        "34: exist,particular,discussion,basis,existence,individual,terms,prove,exists,authority\n",
        "35: written,book,form,study,modern,source,books,specific,according,understanding\n",
        "36: number,end,line,able,sent,details,try,similar,hard,half\n",
        "37: montreal,patrick,cup,series,goal,red,calgary,kings,jersey,quebec\n",
        "38: food,day,cause,water,told,hours,eat,gave,body,months\n",
        "39: don,just,like,think,know,really,things,want,doesn,thing\n",
        "40: common,major,effect,usually,especially,light,level,changes,caused,normal\n",
        "41: bike,ride,road,miles,riding,dod,bikes,motorcycle,honda,rear\n",
        "42: car,cars,engine,air,vehicle,oil,auto,gas,tires,ford\n",
        "43: money,cost,pay,costs,buy,company,tax,business,market,companies\n",
        "44: time,believe,come,reason,hand,feel,quite,idea,talking,ones\n",
        "45: good,probably,great,started,times,thought,lot,close,coming,pretty\n",
        "46: office,california,gov,average,potential,__,college,diego,released,successful\n",
        "47: way,right,course,sure,having,tell,maybe,kind,talk,unless\n",
        "48: new,past,defense,interesting,expect,training,decided,improved,hands,eyes\n",
        "49: night,oh,dead,hell,lead,mouth,king,guy,lose,shit\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also get the column indices instead of the column labels if necessary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_model.get_topics(topic=5, n_words=10, print_words=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "[(19533, 0.098693231114866456),\n",
        " (7615, 0.057837756413923226),\n",
        " (6254, 0.053944761810679746),\n",
        " (7619, 0.051054068565401851),\n",
        " (14422, 0.045818888540261123),\n",
        " (8044, 0.040263613665403278),\n",
        " (16970, 0.040197513607973197),\n",
        " (18843, 0.033932768498652233),\n",
        " (19530, 0.033339739420547118),\n",
        " (8533, 0.030942793635717426)]"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we need to directly access the topic assignments for each word, they can be accessed through **cluster**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print topic_model.clusters\n",
      "print topic_model.clusters.shape # m_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[14 15  5 ...,  5 18 18]\n",
        "(101322L,)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Document Labels"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "CorEx is a *discriminative* model, whereas LDA is a *generative* model. This means that while LDA outputs a probability distribution over each document, CorEx instead estimates the probability a document belongs to a topic given that document's words. As a result, the probabilities across topics for a given document do not have to add up to 1. The estimated probabilities of topics for each document can be accessed through **p_y_given_x**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print topic_model.p_y_given_x.shape # n_docs x k_topics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(11314L, 20L)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also use a softmax to make a binary determination of which documents belong to each topic. These softmax labels can be accessed through **labels**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print topic_model.labels.shape # n_docs x k_topics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(11314L, 20L)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since CorEx does not prescribe a probability distribution of topics over each document, this means that a document could possibly belong to no topics (all 0's across topics in **labels**) or all topics (all 1's across topics in **labels**)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Total Correlation and Model Selection"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Overall TC"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Total correlation is the measure which CorEx tries maximize when constructing the topic model. It can be accessed through **tc** and is reported in nats."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_model.tc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "64.987239143189981"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Model selection:** CorEx starts its algorithm with a random initialization, and so different runs can result in different topic models. One way of finding a better topic model is to restart the CorEx algorithm several times and take the run that has the highest TC value (i.e. the run that produces topcis that are most informative about the documents)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Topic TC"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The overall total correlation is the sum of the total correlation per each topic. These can be accessed through **tcs**. Note the topic TCs are always sorted from high to low for unsupervised CorEx (this is not the case if anchoring is done)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_model.tcs.shape # k_topics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(20L,)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.sum(topic_model.tcs)\n",
      "print topic_model.tc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "50.8693161475\n",
        "50.8693161475\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Selecting number of topics:** one way to choose topics is to observe the distribution of TCs for each topic to see how much each additional topic contributes to the overall TC. We should keep adding topics until additional topics do not significantly add to the overall TC. This is similar to choosing a cutoff eigenvalue when doing topic modeling via LSA."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.bar(range(topic_model.tcs.shape[0]), topic_model.tcs, color = '#f29fe4', width = 0.6)\n",
      "plt.xlabel('Topic', fontsize = 16)\n",
      "plt.ylabel('Total Correlation (nats)', fontsize = 16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "<matplotlib.text.Text at 0x10537128>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEUCAYAAAAx56EeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0xd4142e8>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Pointwise Document TC"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can decompose total correlation further. The topic correlation is the average of the pointwise total correlations for each individual document. The pointwise total correlations can be accessed through **log_z**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_model.log_z.shape # n_docs x k_topics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "(11314L, 20L)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.mean(topic_model.log_z, axis = 0)\n",
      "print topic_model.tcs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 5.45254377  2.47248891  1.79340433  1.60988582  1.4948944   1.41257783\n",
        "  1.41063885  1.36317677  1.27671115  1.21899011  1.16675566  1.15717581\n",
        "  1.152626    1.1351332   1.12386914  1.11377598  1.10844425  1.03710471\n",
        "  0.99635866  0.94752955  0.94462103  0.9001288   0.89461451  0.87822797\n",
        "  0.84624667  0.84076549  0.8278814   0.8156603   0.77584759  0.75668865\n",
        "  0.75469194  0.7221026   0.71657552  0.70810685  0.70645551  0.70629439\n",
        "  0.67542996  0.66824162  0.65078918  0.64613907  0.62718579  0.60923128\n",
        "  0.56516268  0.56040248  0.55870154  0.4960023   0.47461146  0.459287\n",
        "  0.33337232  0.30576535]\n",
        "[ 5.45254377  2.47248891  1.79340433  1.60988582  1.4948944   1.41257783\n",
        "  1.41063885  1.36317677  1.27671115  1.21899011  1.16675566  1.15717581\n",
        "  1.152626    1.1351332   1.12386914  1.11377598  1.10844425  1.03710471\n",
        "  0.99635866  0.94752955  0.94462103  0.9001288   0.89461451  0.87822797\n",
        "  0.84624667  0.84076549  0.8278814   0.8156603   0.77584759  0.75668865\n",
        "  0.75469194  0.7221026   0.71657552  0.70810685  0.70645551  0.70629439\n",
        "  0.67542996  0.66824162  0.65078918  0.64613907  0.62718579  0.60923128\n",
        "  0.56516268  0.56040248  0.55870154  0.4960023   0.47461146  0.459287\n",
        "  0.33337232  0.30576535]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These values represent the correlations explained by a topic for an individual document."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Hierarchical Topic Models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can naturally repeat the CorEx algorithm on the topics to get latent representations of the topics themselves. This yields a hierarchical CorEx topic model. Like the first layer of the topic model, one can determine the number of latent variables to add in higher layers through examination of the topic TCs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train a second layer to the topic model\n",
      "tm_layer2 = ct.Corex(n_hidden=10)\n",
      "tm_layer2.fit(topic_model.labels);\n",
      "\n",
      "# Train a third layer to the topic model\n",
      "tm_layer3 = ct.Corex(n_hidden=1)\n",
      "tm_layer3.fit(tm_layer2.labels);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "WARNING: Some words never appear (or always appear)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you have graphviz installed, then you can output visualizations of the hierarchial topic model to your current working directory. One can also create custom visualizations of the hierarchy by properly making use of the **labels** attribute of each layer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vt.vis_hierarchy([topic_model, tm_layer2, tm_layer3], column_label=starred_words, max_edges=200, prefix='topic-model-example')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Anchoring for Semi-Supervised Topic Modeling"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Anchored CorEx is an extension of CorEx that allows the \"anchoring\" of words to topics. When anchoring a word to a topic, CorEx is trying to maximize the mutual information between that word and the anchored topic. So, anchoring provides a way to guide the topic model towards specific subsets of words that the user would like to explore. The anchoring mechanism is flexible, and so there are many possibilities of anchoring:\n",
      "+ anchoring one word to one topic\n",
      "+ anchoring a group of words to one topic\n",
      "+ anchoring one word to multiple topics\n",
      "+ anchoring multiple groups of words to individual topics\n",
      "+ anchoring to some topics and not others\n",
      "\n",
      "We'll demonstrate how easy it is to anchor the CorEx topic model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Anchor one word to the first topic\n",
      "anchor_words = ['nasa']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Anchor the word 'nasa' to the first topic\n",
      "anchored_topic_model = ct.Corex(n_hidden=20)\n",
      "anchored_topic_model.fit(doc_word, words=words, anchors=anchor_words, anchor_strength=6);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This anchors the single word \"nasa\" to the first topic."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_words,_ = zip(*anchored_topic_model.get_topics(topic=0))\n",
      "print '{}: '.format(n) + ','.join(topic_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3: nasa,space,information,research,following,systems,technology,archive,university,office\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can anchor multiple groups of words to multiple topics as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Anchor 'nasa' and 'space' to first topic, 'sports' and 'stadium' to second topic, so on...\n",
      "anchor_words = [['nasa', 'space'], ['sports', 'stadium'], ['politics', 'government'], ['love', 'hope']]\n",
      "\n",
      "anchored_topic_model = ct.Corex(n_hidden=20)\n",
      "anchored_topic_model.fit(doc_word, words=words, anchors=anchor_words, anchor_strength=6);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "<corex_topic.Corex at 0x1046d518>"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for n in range(len(anchor_words)):\n",
      "    topic_words,_ = zip(*anchored_topic_model.get_topics(topic=n))\n",
      "    print '{}: '.format(n) + ','.join(topic_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: space,nasa,orbit,earth,moon,gov,launch,russian,shuttle,sci\n",
        "1: sports,stadium,1993,15,13,11,18,10,14,17\n",
        "2: government,politics,rights,law,state,war,country,national,states,crime"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3: hope,love,jesus,christ,sin,lord,heaven,holy,helps,spirit\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note, in the above topic model, topics will no longer be sorted according to descending TC. Instead, the first topic will be the one with 'nasa' and 'space' anchored to it, the second topic will be the one with 'sports' and 'stadium' anchored to it, and so on.\n",
      "\n",
      "We can continue to develop even more complicated anchoring strategies. Here we anchor \"nasa\" by itself, as well as in two other topics each with \"politics\" and \"news\". We"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Anchor with single words and groups of words\n",
      "anchor_words = ['nasa', ['nasa', 'politics'], ['nasa', 'news'], ['fear', 'love', 'hope']]\n",
      "\n",
      "anchored_topic_model = ct.Corex(n_hidden=20)\n",
      "anchored_topic_model.fit(doc_word, words=words, anchors=anchor_words, anchor_strength=6);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "<corex_topic.Corex at 0x1046d9e8>"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for n in range(len(anchor_words)):\n",
      "    topic_words,_ = zip(*anchored_topic_model.get_topics(topic=n))\n",
      "    print '{}: '.format(n) + ','.join(topic_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: nasa,research,space,center,1992,international,science,published,university,dr\n",
        "1: nasa,politics,13,15,14,18,11,17,19,21\n",
        "2: news,nasa,1993,april,date,press,office,sent,organization,article"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3: hope,fear,love,people,fact,world,person,human,years,history\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note:** If you do not specify the column word labels, then you can still anchor by specifying the column indices of the features you wish to anchor on. You may also specify anchors using a mix of strings and indices if desired."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Choosing anchor strength:** the anchor strength controls how much weight CorEx puts towards maximizing the mutual information between the anchor words and their respective topics. Anchor strength should always be set at a value *greater than* 1, since setting anchor strength between 0 and 1 only recovers the unsupervised CorEx objective. Empirically, setting anchor strength from 1.5-3 seems to nudge the topic model towards the anchor words. Setting anchor strength >5 is strongly enforcing that the CorEx topic model find a topic associated with the anchor words.\n",
      "\n",
      "We encourage users to experiment with the anchor strength and determine what values are best for their needs."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Other Output"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The *vis_topic* module provides support for outputting topics and visualizations of the CorEx topic model. The code below creates a results direcory named \"twenty\" in your working directory."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vt.vis_rep(topic_model, column_label=words, prefix='twenty')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}